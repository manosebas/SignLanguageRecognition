# Sign Language AI
It continues to develop

## Description
This project focuses on comparing the performance of Convolutional Neural Networks (CNN) and Vision Transformers (ViT) in the classification of sign language images.

The project utilizes datasets with tabular images representing different sign language gestures, each labeled accordingly.

CNNs extract features through convolutional layers, while ViTs divide images into patches and use attention mechanisms for classification.

Additionally, the project includes a live camera feature that allows users to perform sign language gestures in real-time, detecting and identifying the letters being shown.

This combination of deep learning models and real-time detection showcases a robust approach to sign language recognition.

**Note:** This project is still in progress, so it does not yet achieve 100% accuracy.

## Live Detection Screenshots
Here are some images demonstrating the live sign language detection in action:

![Live Detection 1](./images/1.png)
![Live Detection 2](./images/2.png)
![Live Detection 3](./images/3.png)
![Live Detection 4](./images/4.png)
![Live Detection 5](./images/5.png)
![Live Detection 6](./images/6.png)

## Installation
1. Ensure you have Python installed on your system.
2. Install the required libraries listed in `requirements.txt` using:

pip install -r requirements.txt


## Requirements
- Python 3.7 or later
- TensorFlow
- OpenCV
- Other dependencies as listed in `requirements.txt`

## Contributing
Feel free to fork this repository and contribute by submitting a pull request. Improvements in model accuracy or real-time performance are particularly welcome.
